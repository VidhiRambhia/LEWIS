model_info:
  - name: 'meta-llama/Llama-3.1-8B'
    type: 'base'
  - name: 'MathGenie/MathCoder2-Llama-3-8B'
    type: 'math'

dataset: "gsm8k"
    
sparsity_ratio: 0.5

nsamples: 15

components:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj

base_model_type: 'base'
base_model_name: 'meta-llama/Llama-3.1-8B'

target_model_names:
  math: 'MathGenie/MathCoder2-Llama-3-8B'

global_parameters:
  normalize: true
  int8_mask: true

prefix_mapping:
  q_proj: 'self_attn.q_proj'
  k_proj: 'self_attn.k_proj'
  v_proj: 'self_attn.v_proj'
  o_proj: 'self_attn.o_proj'
  gate_proj: 'mlp.gate_proj'
  up_proj: 'mlp.up_proj'
  down_proj: 'mlp.down_proj'
  
